# Data Contract: Scoring Module

## Overview

This document defines the public data contracts for the playbook scoring system. All types are implicit (Python dicts with documented key/value schemas). No formal class definitions are introduced -- the codebase uses plain dicts.

---

## Schema Definitions

### PlaybookEntry

The canonical schema for a single key point in the playbook.

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `name` | `str` | Non-empty. Format: `kpt_NNN` (e.g., `kpt_001`). Unique within a playbook. | Stable identifier for the key point. |
| `text` | `str` | Non-empty. | The key point content (guidance text). |
| `helpful` | `int` | `>= 0` (INV-SCORE-001) | Count of times this key point was rated "helpful" by the reflector. |
| `harmful` | `int` | `>= 0` (INV-SCORE-002) | Count of times this key point was rated "harmful" by the reflector. |

**Absent fields**: The `score` field does NOT exist in canonical entries. If encountered during load, it is migrated and dropped (REQ-SCORE-006, INV-SCORE-004).

**JSON example** (on disk):
```json
{
  "name": "kpt_001",
  "text": "Always use type hints for function signatures",
  "helpful": 5,
  "harmful": 1
}
```

---

### Playbook

The top-level playbook structure stored in `playbook.json`.

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `version` | `str` | Currently `"1.0"`. | Schema version identifier. |
| `last_updated` | `str \| None` | ISO 8601 format when set (e.g., `"2026-02-18T14:30:00.000000"`). `None` for newly created playbooks. | Timestamp of last `save_playbook()` call. |
| `key_points` | `list[PlaybookEntry]` | May be empty. Each entry conforms to the PlaybookEntry schema. | The list of key points. |

**JSON example** (on disk):
```json
{
  "version": "1.0",
  "last_updated": "2026-02-18T14:30:00.000000",
  "key_points": [
    {
      "name": "kpt_001",
      "text": "Always use type hints for function signatures",
      "helpful": 5,
      "harmful": 1
    },
    {
      "name": "kpt_002",
      "text": "Prefer pathlib over os.path for file operations",
      "helpful": 0,
      "harmful": 0
    }
  ]
}
```

**Empty playbook** (returned by `load_playbook()` when file does not exist or is corrupt):
```json
{
  "version": "1.0",
  "last_updated": null,
  "key_points": []
}
```

---

### ExtractionResult

The output of `extract_keypoints()`. **This schema is UNCHANGED by this task** (Assumption A1 in intent.md). Documented here for completeness as it is the input to `update_playbook_data()`.

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `new_key_points` | `list[str]` | May be empty. Each string is non-empty guidance text. | New key points discovered by the reflector LLM. |
| `evaluations` | `list[Evaluation]` | May be empty. | Ratings of existing key points. |

#### Evaluation (sub-schema of ExtractionResult)

| Field | Type | Constraints | Description |
|-------|------|-------------|-------------|
| `name` | `str` | Should match an existing `PlaybookEntry.name`. Unmatched names are silently ignored. | The key point being evaluated. |
| `rating` | `str` | One of `"helpful"`, `"harmful"`, `"neutral"`. Unrecognized values are treated as no-op. | The reflector's assessment of the key point for this session. |

**JSON example** (returned by `extract_keypoints()`):
```json
{
  "new_key_points": [
    "Use structured logging instead of print statements"
  ],
  "evaluations": [
    {"name": "kpt_001", "rating": "helpful"},
    {"name": "kpt_002", "rating": "neutral"},
    {"name": "kpt_003", "rating": "harmful"}
  ]
}
```

---

## Migration Contracts

### Input/Output Mapping for Legacy Formats

`load_playbook()` handles three legacy entry formats found in old `playbook.json` files. Each is migrated to the canonical PlaybookEntry schema on load.

#### Format 1: Bare String

**Input** (in `key_points` array):
```json
"Always use type hints for function signatures"
```

**Output** (after migration):
```json
{
  "name": "kpt_001",
  "text": "Always use type hints for function signatures",
  "helpful": 0,
  "harmful": 0
}
```

**Rules**:
- `name`: Generated by `generate_keypoint_name()` using the set of names already seen
- `text`: The original string, unchanged
- `helpful`: `0` (no evaluation history)
- `harmful`: `0` (no evaluation history)

#### Format 2: Dict Without Score or Counters

**Input** (in `key_points` array):
```json
{
  "name": "kpt_003",
  "text": "Prefer pathlib over os.path"
}
```

**Output** (after migration):
```json
{
  "name": "kpt_003",
  "text": "Prefer pathlib over os.path",
  "helpful": 0,
  "harmful": 0
}
```

**Rules**:
- `name`: Preserved if present; generated if absent
- `text`: Preserved unchanged
- `helpful`: `0` (no evaluation history)
- `harmful`: `0` (no evaluation history)

#### Format 3: Dict With Score

**Input** (in `key_points` array):
```json
{
  "name": "kpt_005",
  "text": "Avoid global state",
  "score": -3
}
```

**Output** (after migration):
```json
{
  "name": "kpt_005",
  "text": "Avoid global state",
  "helpful": 0,
  "harmful": 3
}
```

**Rules**:
- `name`: Preserved if present; generated if absent
- `text`: Preserved unchanged
- `helpful`: `max(score, 0)` -- positive scores map to helpful count
- `harmful`: `max(-score, 0)` -- negative scores map to harmful count
- `score`: **Removed** from the dict (INV-SCORE-004)

**Migration formula examples**:

| Original `score` | `helpful` | `harmful` | Rationale |
|-------------------|-----------|-----------|-----------|
| `5` | `5` | `0` | Positive score -> all helpful signal |
| `0` | `0` | `0` | Zero score -> no signal in either direction |
| `-3` | `0` | `3` | Negative score -> all harmful signal |
| `-7` | `0` | `7` | Deeply negative -> high harmful count |

#### Mixed Format Example

**Input** `playbook.json`:
```json
{
  "version": "1.0",
  "last_updated": "2026-01-15T10:00:00",
  "key_points": [
    "Use type hints",
    {"name": "kpt_002", "text": "Prefer pathlib"},
    {"name": "kpt_003", "text": "Avoid globals", "score": -3},
    {"name": "kpt_004", "text": "Write tests", "helpful": 8, "harmful": 2}
  ]
}
```

**Output** (after `load_playbook()`):
```json
{
  "version": "1.0",
  "last_updated": "2026-01-15T10:00:00",
  "key_points": [
    {"name": "kpt_001", "text": "Use type hints", "helpful": 0, "harmful": 0},
    {"name": "kpt_002", "text": "Prefer pathlib", "helpful": 0, "harmful": 0},
    {"name": "kpt_003", "text": "Avoid globals", "helpful": 0, "harmful": 3},
    {"name": "kpt_004", "text": "Write tests", "helpful": 8, "harmful": 2}
  ]
}
```

Note: `kpt_004` was already in canonical form (had `helpful`/`harmful`), so it passes through unchanged.

---

## Pruning Contract

### Condition

A key point is pruned (removed from the playbook) if and only if **both** of the following are true:

```python
harmful >= 3  AND  harmful > helpful
```

### Boolean Expression (Python)

```python
should_prune = (kp["harmful"] >= 3) and (kp["harmful"] > kp["helpful"])
```

### Guard Condition

The `harmful >= 3` floor inherently prevents pruning of zero-evaluation entries (`helpful=0, harmful=0`) because `0 >= 3` is `False`. No separate guard branch is needed, but this invariant is explicitly documented (INV-SCORE-003).

### Decision Table

| `helpful` | `harmful` | `harmful >= 3` | `harmful > helpful` | **Pruned?** |
|-----------|-----------|-----------------|---------------------|-------------|
| 0 | 0 | False | False | **No** (zero evaluations) |
| 0 | 2 | False | True | **No** (below floor) |
| 0 | 3 | True | True | **Yes** |
| 1 | 4 | True | True | **Yes** |
| 10 | 4 | True | False | **No** (majority helpful) |
| 3 | 3 | True | False | **No** (equal, not majority harmful) |
| 5 | 6 | True | True | **Yes** |
| 0 | 100 | True | True | **Yes** |

### When Pruning Occurs

Pruning is applied as the final step of `update_playbook_data()`, after all counter increments have been applied. This means a single call to `update_playbook_data()` can:
1. Add new key points (with `helpful=0, harmful=0`)
2. Increment counters on existing key points
3. Prune entries that now meet the pruning condition

New key points added in step 1 are never pruned in step 3 of the same call because they start with `harmful=0` which fails the `harmful >= 3` floor check.

---

## Formatted Output Contract

### Format String

```python
f"[{kp['name']}] helpful={kp['helpful']} harmful={kp['harmful']} :: {kp['text']}"
```

### Example Output (injected into prompt via template)

```
[kpt_001] helpful=5 harmful=1 :: Always use type hints for function signatures
[kpt_002] helpful=0 harmful=0 :: Prefer pathlib over os.path for file operations
[kpt_003] helpful=12 harmful=3 :: Write unit tests before implementation
```

### Parsing Contract (for Claude's interpretation)

The format is designed so that Claude (the LLM reading the prompt) can:
- Identify each key point by its `[name]` tag
- Read the `helpful=N` and `harmful=N` counts
- Access the guidance text after the `::` delimiter
- Compute an informal trust ratio (e.g., `helpful / (helpful + harmful)`) to decide how much weight to give each key point
